"""LLM-based validation engine using GPT-5.1 reasoning with requirements-mamad.md."""
import json
from typing import List, Dict, Any, Optional
from pathlib import Path

from src.models import (
    ExtractedPlanData,
    ValidationViolation,
    ValidationResult,
    ValidationStatus,
    ValidationSeverity,
    BoundingBox,
    IndividualCheck,
    CheckStatus,
)
from src.azure.openai_client import get_openai_client
from src.utils.logging import get_logger

logger = get_logger(__name__)


class LLMValidator:
    """Validation engine powered by GPT-5.1 reasoning against requirements-mamad.md."""
    
    def __init__(self, requirements_path: str = "requirements-mamad.md"):
        """Initialize LLM validator.
        
        Args:
            requirements_path: Path to requirements markdown file
        """
        self.requirements_path = Path(requirements_path)
        self.openai_client = get_openai_client()
        
        # Load requirements content
        if not self.requirements_path.exists():
            raise FileNotFoundError(f"Requirements file not found: {self.requirements_path}")
        
        self.requirements_content = self.requirements_path.read_text(encoding="utf-8")
        logger.info("LLM Validator initialized", 
                   requirements_file=str(self.requirements_path),
                   requirements_length=len(self.requirements_content))
    
    def validate(
        self,
        validation_id: str,
        project_id: str,
        plan_name: str,
        plan_blob_url: str,
        extracted_data: ExtractedPlanData,
        plan_image_bytes: Optional[bytes] = None,
    ) -> ValidationResult:
        """Run validation using GPT-5.1 against requirements-mamad.md.
        
        Args:
            validation_id: Unique validation ID
            project_id: Project identifier
            plan_name: Name of the architectural plan
            plan_blob_url: Azure Blob Storage URL
            extracted_data: Data extracted from the plan by GPT-5.1
            plan_image_bytes: Optional image bytes for visual bounding box identification
            
        Returns:
            Complete ValidationResult with all violations
        """
        logger.info("Starting LLM-based validation", 
                   validation_id=validation_id,
                   project_id=project_id)
        
        try:
            # Step 0: Identify Mamad location (sanity check)
            mamad_identification = None
            if plan_image_bytes:
                logger.info("Running Mamad identification check")
                mamad_identification = self._identify_mamad_sync(
                    plan_image_bytes=plan_image_bytes,
                    extracted_data=extracted_data
                )
            
            # Build prompt for GPT-5.1 (include Mamad identification from Step 0)
            prompt = self._build_validation_prompt(extracted_data, mamad_identification)
        
            # Build messages for GPT-5.1
            messages = [
                {
                    "role": "system",
                    "content": self._get_system_prompt()
                },
                {
                    "role": "user",
                    "content": [
                        {
                            "type": "text",
                            "text": prompt
                        }
                    ]
                }
            ]
            
            # If we have the image, include it so GPT can provide bounding boxes
            if plan_image_bytes:
                import base64
                base64_image = base64.b64encode(plan_image_bytes).decode('utf-8')
                messages[1]["content"].append({
                    "type": "image_url",
                    "image_url": {
                        "url": f"data:image/jpeg;base64,{base64_image}"
                    }
                })
            
            # Call GPT-5.1 for validation
            response = self.openai_client.client.chat.completions.create(
                model="gpt-5.1",
                messages=messages
            )
            
            # Parse response
            response_text = response.choices[0].message.content
            logger.info("GPT-5.1 validation completed", 
                       response_length=len(response_text))
            
            # Extract JSON from response
            violations = self._parse_validation_response(response_text)
            
            # Build result with individual checks
            result = self._build_validation_result(
                validation_id=validation_id,
                project_id=project_id,
                plan_name=plan_name,
                plan_blob_url=plan_blob_url,
                extracted_data=extracted_data,
                violations=violations,
                mamad_identification=mamad_identification
            )
            
            logger.info("Validation completed",
                       status=result.status.value,
                       total_checks=result.total_checks,
                       failed_checks=result.failed_checks)
            
            return result
            
        except Exception as e:
            logger.error("Validation failed", error=str(e), validation_id=validation_id)
            raise
    
    async def identify_mamad_location(
        self,
        plan_blob_url: str,
        extracted_data: ExtractedPlanData
    ) -> Dict[str, Any]:
        """Identify and locate the Mamad room in the architectural plan.
        
        This is a sanity check to ensure the system is analyzing the correct room.
        Returns bounding box of the identified Mamad.
        
        Args:
            plan_blob_url: URL to the plan image
            extracted_data: Extracted plan data
            
        Returns:
            Dict with: identified (bool), room_label (str), bounding_box (BoundingBox), confidence (float)
        """
        logger.info("Starting Mamad identification sanity check")
        
        prompt = f"""× ×ª×•× ×™× ×©×–×•×”×•:
- ××¡×¤×¨ ×§×™×¨×•×ª ×—×™×¦×•× ×™×™×: {extracted_data.external_wall_count}
- ×¢×•×‘×™ ×§×™×¨×•×ª: {extracted_data.wall_thickness_cm}
- ×’×•×‘×” ×—×“×¨: {extracted_data.room_height_m}

**××©×™××”:**
1. ×–×”×” ××ª ×—×“×¨ ×”××"×“ ×‘×ª×•×›× ×™×ª ×”××“×¨×™×›×œ×™×ª
2. ×•×“× ×©××ª×” ×× ×ª×— ××ª ×”×—×“×¨ ×”× ×›×•×Ÿ ×•×œ× ×©×™×¨×•×ª×™×/××¨×•×Ÿ/××—×¡×Ÿ
3. ×¡××Ÿ ××ª ×”××"×“ ×‘××œ×‘×Ÿ ××“×•×

**×”×—×–×¨ JSON:**
{{
  "identified": true/false,
  "room_label": "×ª×™××•×¨ ×”×—×“×¨ ×©×–×•×”×” (×œ××©×œ: '×××´×“ - ×—×“×¨ 4x6 ××˜×¨')",
  "confidence": 0.0-1.0,
  "bounding_box": {{"x": float, "y": float, "width": float, "height": float}},
  "reasoning": "×”×¡×‘×¨ ××™×š ×–×™×”×™×ª ××ª ×”×××´×“ ×•××“×•×¢ ××ª×” ×‘×˜×•×— ×©×–×” ×œ× ×©×™×¨×•×ª×™×/××—×¡×Ÿ"
}}"""
        
        try:
            response = self.openai_client.client.chat.completions.create(
                model="gpt-5.1",
                messages=[
                    {
                        "role": "system",
                        "content": "××ª×” ××•××—×” ×œ×–×™×”×•×™ ×—×“×¨×™ ××\"×“ ×‘×ª×•×›× ×™×•×ª ××“×¨×™×›×œ×™×•×ª. ×ª×¤×§×™×“×š ×œ×•×•×“× ×©×”××¢×¨×›×ª ×× ×ª×—×ª ××ª ×”×—×“×¨ ×”× ×›×•×Ÿ."
                    },
                    {
                        "role": "user",
                        "content": prompt
                    }
                ]
            )
            
            response_text = response.choices[0].message.content
            
            # Parse JSON
            json_start = response_text.find("{")
            json_end = response_text.rfind("}") + 1
            json_text = response_text[json_start:json_end]
            result = json.loads(json_text)
            
            logger.info("Mamad identification completed", 
                       identified=result.get("identified"),
                       confidence=result.get("confidence"))
            
            return result
            
        except Exception as e:
            logger.error("Mamad identification failed", error=str(e))
            return {
                "identified": False,
                "room_label": "×©×’×™××” ×‘×–×™×”×•×™",
                "confidence": 0.0,
                "bounding_box": None,
                "reasoning": f"×©×’×™××”: {str(e)}"
            }
    
    def _identify_mamad_sync(
        self,
        plan_image_bytes: bytes,
        extracted_data: ExtractedPlanData
    ) -> Dict[str, Any]:
        """Synchronous version: Identify and locate the Mamad room.
        
        This is Check #0 - sanity check to ensure we're analyzing the correct room.
        
        Args:
            plan_image_bytes: Image bytes of the architectural plan
            extracted_data: Extracted plan data
            
        Returns:
            Dict with: identified (bool), room_label (str), bounding_box (dict), confidence (float)
        """
        logger.info("Starting Mamad identification sanity check")
        
        import base64
        base64_image = base64.b64encode(plan_image_bytes).decode('utf-8')
        
        prompt = f"""**××©×™××” ×§×¨×™×˜×™×ª - ×–×™×”×•×™ ×××´×“:**

× ×ª×•× ×™× ×©×–×•×”×• ×‘×©×œ×‘ ×¨××©×•×Ÿ:
- ××¡×¤×¨ ×§×™×¨×•×ª ×—×™×¦×•× ×™×™×: {extracted_data.external_wall_count if extracted_data.external_wall_count else "×œ× ×–×•×”×”"}
- ×¢×•×‘×™ ×§×™×¨×•×ª: {extracted_data.wall_thickness_cm if extracted_data.wall_thickness_cm else "×œ× ×–×•×”×”"}
- ×’×•×‘×” ×—×“×¨: {extracted_data.room_height_m if extracted_data.room_height_m else "×œ× ×–×•×”×”"} ××˜×¨

**×—×©×•×‘ ×××•×“:** ×–×• ×ª×•×›× ×™×ª ××“×¨×™×›×œ×™×ª ×©×œ ×“×™×¨×ª ××’×•×¨×™× ×©×™×© ×‘×” ××"×“. ××ª×” **×—×™×™×‘** ×œ××¦×•× ××•×ª×•!

**×ª×”×œ×™×š ×”×–×™×”×•×™:**
1. **×¡×¨×•×§ ××ª ×›×œ ×”×ª×•×›× ×™×ª** - ×—×¤×© ×—×“×¨×™× ×¢× ×§×™×¨×•×ª ×¢×‘×™× (×©×—×•×¨×™× ××•×“×’×©×™×)
2. **×–×”×” ××ª ×”×—×“×¨ ×¢× ×”×§×™×¨×•×ª ×”×›×™ ×¢×‘×™×** - ×–×” ×›× ×¨××” ×”×××´×“
3. **××œ ×ª×ª×‘×œ×‘×œ:** 
   - ×©×™×¨×•×ª×™× = ×—×“×¨ ×§×˜×Ÿ ×¢× ××¡×œ×”/××§×œ×—×ª (×¡×™××Ÿ ×¡× ×™×˜×¨×™)
   - ××—×¡×Ÿ = ××¡×•××Ÿ "××—×¡×Ÿ" ××• ×§×˜×Ÿ ×××•×“
   - ××˜×‘×— = ×™×© ×›×™×•×¨/××¨×•× ×•×ª ××˜×‘×—
   - ×××´×“ = ×—×“×¨ ×¨×’×™×œ ×¢× ×§×™×¨×•×ª ×¢×‘×™× ×‘××™×•×—×“
4. **××“×•×“ ×‘×“×™×•×§** ××ª ×”××œ×‘×Ÿ ×”×ª×•×—× (×¨×©×ª 100x100)

**×¡×™×× ×™× ×—×–×§×™× ×œ×××´×“:**
- âœ… ×§×™×¨×•×ª ×¢×‘×™× (20-40 ×¡×´×) - ×”×©×—×•×¨×™× ×‘×™×•×ª×¨ ×‘×ª×•×›× ×™×ª
- âœ… ×œ×¤×—×•×ª 2 ×§×™×¨×•×ª ×—×™×¦×•× ×™×™× (×§×¦×” ×”×“×™×¨×”)
- âœ… ×’×•×“×œ ×©×œ ×—×“×¨ ×©×™× ×” (6-12 ××´×¨)
- âœ… ×™×›×•×œ ×œ×”×™×•×ª ××¡×•××Ÿ "×××´×“" ××• "×.×.×“"
- âœ… ××™×Ÿ ×¡×™×× ×™ ×¡× ×™×˜×¦×™×” (××¡×œ×”/××§×œ×—×ª)

**×”×—×–×¨ JSON:**
{{
  "identified": true,  // ×›××¢×˜ ×ª××™×“ true - ××œ× ×× ×”×ª××•× ×” ×œ× ×‘×¨×•×¨×” ×‘×›×œ×œ
  "room_label": "×××´×“ - ×—×“×¨ X ××´×¨",
  "confidence": 0.0-1.0,  // 0.9+ = ×‘×˜×•×— ×××•×“, 0.7-0.9 = ×¡×‘×™×¨, ××ª×—×ª ×œ-0.7 = ×œ× ×‘×˜×•×—
  "bounding_box": {{"x": 10.0, "y": 15.0, "width": 20.0, "height": 25.0}},
  "reasoning": "×”×¡×‘×¨ ××¤×•×¨×˜: ×”×™×›×Ÿ ××¦××ª×™ ××ª ×”×××´×“, ××™×š ×× ×™ ×™×•×“×¢ ×©×–×” ×œ× ×©×™×¨×•×ª×™×/××—×¡×Ÿ"
}}

**×”×•×¨××•×ª ×œ××“×™×“×ª bounding_box (×‘××—×•×–×™× 0-100):**
- x = ××¨×—×§ ××”×©×××œ (0=×©×××œ, 100=×™××™×Ÿ)
- y = ××¨×—×§ ××œ××¢×œ×” (0=×œ××¢×œ×”, 100=×œ××˜×”)
- width = ×¨×•×—×‘ ×”×—×“×¨ ×‘××—×•×–×™× ××¨×•×—×‘ ×”×ª××•× ×”
- height = ×’×•×‘×” ×”×—×“×¨ ×‘××—×•×–×™× ××’×•×‘×” ×”×ª××•× ×”

**×¨×§ ×‘××§×¨×” ×©×”×ª××•× ×” ×œ× ×‘×¨×•×¨×” ×‘×›×œ×œ** (××˜×•×©×˜×©×ª/×—×¡×¨×”) - `identified: false`"""
        
        try:
            response = self.openai_client.client.chat.completions.create(
                model="gpt-5.1",
                messages=[
                    {
                        "role": "system",
                        "content": "××ª×” ××•××—×” ××“×¨×™×›×œ×•×ª ×¢× × ×™×¡×™×•×Ÿ ×¨×‘ ×‘×§×¨×™××ª ×ª×•×›× ×™×•×ª ×™×©×¨××œ×™×•×ª. ×‘××™×•×—×“, ××ª×” ××ª××—×” ×‘×–×™×”×•×™ ×—×“×¨×™ ×××´×“ (××¨×—×‘ ××•×’×Ÿ ×“×™×¨×ª×™) - ×—×“×¨×™× ×¢× ×§×™×¨×•×ª ××—×•×–×§×™×. ×›×œ ×“×™×¨×” ×‘×™×©×¨××œ ×—×™×™×‘×ª ×œ×›×œ×•×œ ×××´×“ ××—×“ ×œ×¤×—×•×ª. ×ª×¤×§×™×“×š: (1) ×œ××¦×•× ××ª ×”×××´×“ ×‘×ª×•×›× ×™×ª - ×ª××™×“ ×™×© ××—×“! (2) ×œ×”×‘×“×™×œ ×‘×™× ×• ×œ×‘×™×Ÿ ×©×™×¨×•×ª×™×/××—×¡×Ÿ, (3) ×œ××“×•×“ ××ª ××™×§×•××• ×‘×“×™×•×§. ×—×©×•×‘: ×”×ª××•× ×” ×©××ª×” ×¨×•××” ×”×™× ×¨×©×ª 100x100 - ×¡×¤×•×¨ ×‘××—×•×–×™× ××”×©×•×œ×™×™×."
                    },
                    {
                        "role": "user",
                        "content": [
                            {
                                "type": "text",
                                "text": prompt
                            },
                            {
                                "type": "image_url",
                                "image_url": {
                                    "url": f"data:image/jpeg;base64,{base64_image}"
                                }
                            }
                        ]
                    }
                ]
            )
            
            response_text = response.choices[0].message.content
            logger.info("Mamad identification GPT response received", 
                       response_length=len(response_text),
                       full_response=response_text[:1000])  # Log first 1000 chars for debugging
            
            # Parse JSON
            json_start = response_text.find("{")
            json_end = response_text.rfind("}") + 1
            
            if json_start == -1 or json_end == 0:
                logger.error("No JSON in Mamad identification response")
                return {
                    "identified": False,
                    "room_label": "×œ× ×–×•×”×”",
                    "confidence": 0.0,
                    "bounding_box": None,
                    "reasoning": "×”××•×“×œ ×œ× ×”×—×–×™×¨ JSON ×ª×§×™×Ÿ"
                }
            
            json_text = response_text[json_start:json_end]
            result = json.loads(json_text)
            
            # ×”××¨ bounding box ×-0-1 ×œ-0-100 ×× ×¦×¨×™×š
            if result.get("bounding_box"):
                bbox = result["bounding_box"]
                # ×× ×”×¢×¨×›×™× ×§×˜× ×™× ×-1, ×›× ×¨××” ×©×”× ×‘×˜×•×•×— 0-1 ×•×¦×¨×™×š ×œ×”×›×¤×™×œ ×‘-100
                if bbox.get("x", 100) < 1 or bbox.get("y", 100) < 1:
                    logger.info("Converting bounding box from 0-1 to 0-100 range")
                    result["bounding_box"] = {
                        "x": bbox.get("x", 0) * 100,
                        "y": bbox.get("y", 0) * 100,
                        "width": bbox.get("width", 0) * 100,
                        "height": bbox.get("height", 0) * 100
                    }
            
            logger.info("Mamad identification completed", 
                       identified=result.get("identified"),
                       confidence=result.get("confidence"),
                       room_label=result.get("room_label"),
                       bounding_box=result.get("bounding_box"))
            
            return result
            
        except Exception as e:
            logger.error("Mamad identification failed", error=str(e))
            return {
                "identified": False,
                "room_label": "×©×’×™××” ×‘×–×™×”×•×™",
                "confidence": 0.0,
                "bounding_box": None,
                "reasoning": f"×©×’×™××” ×˜×›× ×™×ª: {str(e)}"
            }
    
    def _get_system_prompt(self) -> str:
        """Get system prompt for GPT-5.1."""
        return f"""××ª×” ××•××—×” ×œ×‘×“×™×§×ª ×ª×•×›× ×™×•×ª ××“×¨×™×›×œ×™×•×ª ×©×œ ××"×“ (××¨×—×‘ ××•×’×Ÿ ×“×™×¨×ª×™) ×‘×”×ª×× ×œ×“×¨×™×©×•×ª ×¤×™×§×•×“ ×”×¢×•×¨×£.

×ª×¤×§×™×“×š: ×œ×‘×“×•×§ ××ª ×”× ×ª×•× ×™× ×©×–×•×”×• ×‘×ª×•×›× ×™×ª ×”××“×¨×™×›×œ×™×ª ××œ ××•×œ ××¡××š ×”×“×¨×™×©×•×ª ×”××œ×.

# ××¡××š ×”×“×¨×™×©×•×ª ×”××œ× (requirements-mamad.md):

{self.requirements_content}

---

**×”×•×¨××•×ª:**

1. ×‘×“×•×§ ××ª ×›×œ ×”× ×ª×•× ×™× ×©×–×•×”×• ×‘×ª×•×›× ×™×ª ××œ ××•×œ ×›×œ ×¡×¢×™×£ ×‘××¡××š ×”×“×¨×™×©×•×ª
2. ×–×”×” ×›×œ ×”×¤×¨×”/×—×¨×™×’×” ××”×“×¨×™×©×•×ª
3. ×¢×‘×•×¨ ×›×œ ×”×¤×¨×”, ×¦×™×™×Ÿ:
   - rule_id: ××–×”×” ×”×›×œ×œ (×œ××©×œ: "1.2_wall_thickness")
   - section: ××¡×¤×¨ ×”×¡×¢×™×£ (×œ××©×œ: "1.2")
   - category: ×§×˜×’×•×¨×™×” (×œ××©×œ: "wall_thickness", "room_height", "door_spacing")
   - severity: ×¨××ª ×—×•××¨×” - "critical" (×§×¨×™×˜×™), "major" (××©××¢×•×ª×™), ××• "minor" (×§×œ)
   - description: ×ª×™××•×¨ ×”×”×¤×¨×” ×‘×¢×‘×¨×™×ª
   - field: ×”×©×“×” ×©× ×‘×“×§
   - actual_value: ×”×¢×¨×š ×‘×¤×•×¢×œ ×©×–×•×”×”
   - expected_value: ×”×¢×¨×š ×”× ×“×¨×© ×œ×¤×™ ×”×“×¨×™×©×•×ª
   - reasoning: ×”×¡×‘×¨ ××¤×•×¨×˜ ×œ××” ×–×• ×”×¤×¨×”
   - location_description: ×ª×™××•×¨ ××“×•×™×§ ×©×œ ×”××™×§×•× ×‘×ª×•×›× ×™×ª (×œ××©×œ: "×”×“×œ×ª ×”×××•×§××ª ×‘×§×™×¨ ×”×¢×œ×™×•×Ÿ ×©×œ ×”×××´×“, ×‘××¨×›×– ×”×ª×•×›× ×™×ª")
   - bounding_box: **×—×•×‘×”** - ×–×”×” ××ª ×”××™×§×•× ×”××“×•×™×§ ×‘×ª××•× ×” ×›××—×•×–×™×:
     * ××¢×¨×›×ª ×§×•××•×¨×“×™× ×˜×•×ª: (0,0) = ×¤×™× ×” ×©×××œ×™×ª ×¢×œ×™×•× ×”, (100,100) = ×¤×™× ×” ×™×× ×™×ª ×ª×—×ª×•× ×”
     * x: ××—×•×– ×”××¨×—×§ ××§×¦×” ×©×××œ ×©×œ ×”×ª××•× ×” (0-100)
     * y: ××—×•×– ×”××¨×—×§ ××§×¦×” ×¢×œ×™×•×Ÿ ×©×œ ×”×ª××•× ×” (0-100)
     * width: ××—×•×– ×¨×•×—×‘ ×”××œ×× ×˜ ×‘×™×—×¡ ×œ×¨×•×—×‘ ×”×ª××•× ×” (0-100)
     * height: ××—×•×– ×’×•×‘×” ×”××œ×× ×˜ ×‘×™×—×¡ ×œ×’×•×‘×” ×”×ª××•× ×” (0-100)
     * **×“×•×’×××•×ª ×§×•× ×§×¨×˜×™×•×ª:**
       - ×“×œ×ª ×‘×§×™×¨ ×”×¢×œ×™×•×Ÿ ×‘××¨×›×–: {{"x": 40, "y": 5, "width": 15, "height": 8}}
       - ×§×™×¨ ×©×××œ×™: {{"x": 5, "y": 10, "width": 3, "height": 75}}
       - ×—×œ×•×Ÿ ×‘×§×™×¨ ×™×× ×™: {{"x": 85, "y": 20, "width": 10, "height": 12}}
       - ×›×œ ×”×—×“×¨: {{"x": 10, "y": 10, "width": 80, "height": 80}}
     * ×× ×œ× × ×™×ª×Ÿ ×œ×–×”×•×ª ××™×§×•× - ×”×©×ª××© ×‘-null

4. **×“×•×’××” ×œ×”×¤×¨×” ××œ××”:**
{{
  "rule_id": "2.2_door_spacing",
  "section": "2.2",
  "category": "door_spacing",
  "severity": "major",
  "description": "××¨×•×•×— ×‘×™×Ÿ ×“×œ×ª ×”×××´×“ ×œ×“×œ×ª ×”×“×™×¨×”: 30 ×¡×´× ×‘××§×•× 90 ×¡×´× × ×“×¨×©",
  "field": "door_spacing_cm",
  "actual_value": "30",
  "expected_value": "90",
  "reasoning": "×”××¨×•×•×— ×”× ××“×“ ×‘×™×Ÿ ×”×“×œ×ª×•×ª ×§×˜×Ÿ ××”× ×“×¨×©, ××” ×©×¢×œ×•×œ ×œ×¤×’×•×¢ ×‘×™×¢×™×œ×•×ª ×”××˜×™××”",
  "location_description": "×”×“×œ×ª ×©×œ ×”×××´×“ ×‘×§×™×¨ ×”×¢×œ×™×•×Ÿ, ×§×¨×•×‘ ××“×™ ×œ×“×œ×ª ×”×›× ×™×¡×” ×”×¨××©×™×ª",
  "bounding_box": {{"x": 42, "y": 8, "width": 12, "height": 6}}
}}

5. ×”×—×–×¨ ×ª×©×•×‘×” ×‘×¤×•×¨××˜ JSON ×‘×œ×‘×“:
{{
  "violations": [
    {{
      "rule_id": "1.2_wall_thickness",
      "section": "1.2",
      "category": "wall_thickness",
      "severity": "critical",
      "description": "×¢×•×‘×™ ×§×™×¨×•×ª: 35 ×¡×´× ×‘××§×•× 40 ×¡×´× × ×“×¨×© (4 ×§×™×¨×•×ª ×—×•×¥)",
      "field": "wall_thickness_cm",
      "actual_value": "35",
      "expected_value": "40",
      "reasoning": "×–×•×”×• 4 ×§×™×¨×•×ª ×—×•×¥, ×œ×›×Ÿ × ×“×¨×© ×¢×•×‘×™ ×©×œ 40 ×¡×´× ×œ×¤×™ ×¡×¢×™×£ 1.2",
      "location_description": "×›×œ 4 ×§×™×¨×•×ª ×”×—×™×¦×•× ×™×™× ×©×œ ×”×××´×“",
      "bounding_box": {{"x": 10, "y": 15, "width": 80, "height": 75}}
    }},
    {{
      "rule_id": "2.2_door_spacing",
      "section": "2.2",
      "category": "door_spacing",
      "severity": "major",
      "description": "××¨×•×•×— ×‘×™×Ÿ ×“×œ×ª ×”×××´×“ ×œ×“×œ×ª ×”×“×™×¨×”: 30 ×¡×´× ×‘××§×•× 90 ×¡×´×",
      "field": "door_spacing_cm",
      "actual_value": "30",
      "expected_value": "90",
      "reasoning": "×”××¨×•×•×— ×§×˜×Ÿ ××“×™ ×•×¢×œ×•×œ ×œ×¤×’×•×¢ ×‘××˜×™××•×ª",
      "location_description": "×”×“×œ×ª ×‘×§×™×¨ ×”×¢×œ×™×•×Ÿ ×©×œ ×”×××´×“",
      "bounding_box": {{"x": 42, "y": 8, "width": 12, "height": 6}}
    }}
  ],
  "total_checks_performed": 20,
  "reasoning_summary": "×‘×•×¦×¢×• 20 ×‘×“×™×§×•×ª, × ××¦××• 2 ×”×¤×¨×•×ª",
  "mamad_identified": {{
    "room_label": "×××´×“ - ×—×“×¨ 6x4 ××˜×¨",
    "bounding_box": {{"x": 15, "y": 20, "width": 70, "height": 65}}
  }}
}}

**×—×©×•×‘:** ×× ××™×Ÿ ×”×¤×¨×•×ª, ×”×—×–×¨ ××¢×¨×š violations ×¨×™×§.
"""
    
    def _build_validation_prompt(self, extracted_data: ExtractedPlanData, mamad_identification: Optional[Dict[str, Any]] = None) -> str:
        """Build validation prompt with extracted data and Mamad location from Step 0."""
        
        data_dict = {
            "external_wall_count": extracted_data.external_wall_count,
            "wall_thickness_cm": extracted_data.wall_thickness_cm,
            "wall_with_window": extracted_data.wall_with_window,
            "room_height_m": extracted_data.room_height_m,
            "room_volume_m3": extracted_data.room_volume_m3,
            "door_spacing_internal_cm": extracted_data.door_spacing_internal_cm,
            "door_spacing_external_cm": extracted_data.door_spacing_external_cm,
            "window_spacing_cm": extracted_data.window_spacing_cm,
            "window_to_door_spacing_cm": extracted_data.window_to_door_spacing_cm,
            "has_ventilation_note": extracted_data.has_ventilation_note,
            "has_air_inlet_pipe": extracted_data.has_air_inlet_pipe,
            "has_air_outlet_pipe": extracted_data.has_air_outlet_pipe,
            "annotations": extracted_data.annotations,
            "confidence_score": extracted_data.confidence_score
        }
        
        # Build base prompt
        prompt = f"""# × ×ª×•× ×™× ×©×–×•×”×• ×‘×ª×•×›× ×™×ª ×”××“×¨×™×›×œ×™×ª:

```json
{json.dumps(data_dict, ensure_ascii=False, indent=2)}
```
"""
        
        # Add Mamad identification from Step 0 if available
        if mamad_identification and mamad_identification.get("identified"):
            bbox = mamad_identification.get("bounding_box", {})
            prompt += f"""

# ğŸ¯ **××™×§×•× ×”×××´×“ ×©×–×•×”×” (×©×œ×‘ 0):**

**×—×©×•×‘ ×××•×“:** ×”×××´×“ ×›×‘×¨ ×–×•×”×” ×‘×©×œ×‘ ×§×•×“×. ×”×©×ª××© ×‘××™×“×¢ ×”×–×”!

- **×ª×™××•×¨:** {mamad_identification.get('room_label', '×œ× ×–×•×”×”')}
- **××™×§×•× ×‘×ª××•× ×”:** x={bbox.get('x', 0):.1f}%, y={bbox.get('y', 0):.1f}%, ×¨×•×—×‘={bbox.get('width', 0):.1f}%, ×’×•×‘×”={bbox.get('height', 0):.1f}%
- **×”×¡×‘×¨:** {mamad_identification.get('reasoning', '')}
- **×¨××ª ×‘×™×˜×—×•×Ÿ:** {mamad_identification.get('confidence', 0)*100:.0f}%

**×›×œ ×”×‘×“×™×§×•×ª ×¦×¨×™×›×•×ª ×œ×”×ª×‘×¦×¢ ×¢×œ ×”×—×“×¨ ×”×–×” ×‘×“×™×•×§!** 
××œ ×ª×—×¤×© ××ª ×”×××´×“ ××—×“×© - ×”×•× ×›×‘×¨ ××¡×•××Ÿ ×‘×§×•××•×¨×“×™× ×˜×•×ª ×œ××¢×œ×”.
"""
        
        prompt += """
×‘×“×•×§ ××ª ×›×œ ×”× ×ª×•× ×™× ×”×œ×œ×• ××œ ××•×œ ××¡××š ×”×“×¨×™×©×•×ª ×”××œ× ×©×§×™×‘×œ×ª ×‘×”×•×“×¢×ª ×”××¢×¨×›×ª.
×–×”×” ××ª ×›×œ ×”×”×¤×¨×•×ª ×•×”×—×–×¨ ×ª×©×•×‘×” ×‘×¤×•×¨××˜ JSON ×›×¤×™ ×©×”×•×’×“×¨.
"""
        
        return prompt
    
    def _parse_validation_response(self, response_text: str) -> List[ValidationViolation]:
        """Parse GPT-5.1 validation response into violations list."""
        
        try:
            # Extract JSON from response (handle markdown code blocks)
            json_start = response_text.find("{")
            json_end = response_text.rfind("}") + 1
            
            if json_start == -1 or json_end == 0:
                logger.error("No JSON found in response", response=response_text[:200])
                return []
            
            json_text = response_text[json_start:json_end]
            data = json.loads(json_text)
            
            # Log the parsed response to debug bounding boxes
            logger.info("GPT Response Parsed", 
                       violations_count=len(data.get("violations", [])),
                       first_violation_keys=list(data.get("violations", [{}])[0].keys()) if data.get("violations") else [],
                       has_bounding_boxes=any(v.get("bounding_box") for v in data.get("violations", [])))
            
            violations = []
            for v in data.get("violations", []):
                # Map severity string to enum
                severity_map = {
                    "critical": ValidationSeverity.CRITICAL,
                    "major": ValidationSeverity.MAJOR,
                    "minor": ValidationSeverity.MINOR
                }
                severity = severity_map.get(v.get("severity", "major"), ValidationSeverity.MAJOR)
                
                # Parse bounding box if provided
                bbox_data = v.get("bounding_box")
                bounding_box = None
                if bbox_data and isinstance(bbox_data, dict):
                    try:
                        from src.models.schemas import BoundingBox
                        bounding_box = BoundingBox(**bbox_data)
                    except Exception as e:
                        logger.warning("Failed to parse bounding box", error=str(e), bbox=bbox_data)
                
                violation = ValidationViolation(
                    rule_id=v.get("rule_id", "unknown"),
                    section_reference=v.get("section", "unknown"),
                    category=v.get("category", "unknown"),
                    severity=severity,
                    description=v.get("description", ""),
                    actual_value=str(v.get("actual_value", "")),
                    expected_value=str(v.get("expected_value", "")),
                    location_description=v.get("location_description"),
                    bounding_box=bounding_box
                )
                violations.append(violation)
            
            logger.info("Parsed validation response",
                       violations_count=len(violations),
                       total_checks=data.get("total_checks_performed", 0))
            
            return violations
            
        except json.JSONDecodeError as e:
            logger.error("Failed to parse validation JSON", 
                        error=str(e),
                        response=response_text[:500])
            return []
        except Exception as e:
            logger.error("Failed to parse validation response",
                        error=str(e))
            return []
    
    def _build_validation_result(
        self,
        validation_id: str,
        project_id: str,
        plan_name: str,
        plan_blob_url: str,
        extracted_data: ExtractedPlanData,
        violations: List[ValidationViolation],
        mamad_identification: Optional[Dict[str, Any]] = None
    ) -> ValidationResult:
        """Build final validation result with individual checks."""
        
        checks = []
        
        # Check 0: Sanity check - Mamad identification
        if mamad_identification:
            bbox = mamad_identification.get("bounding_box")
            is_identified = mamad_identification.get("identified", False)
            confidence = mamad_identification.get("confidence", 0)
            
            # Only show bounding box if Mamad was successfully identified
            bbox_obj = None
            if is_identified and bbox and isinstance(bbox, dict):
                # Verify bbox has non-zero dimensions
                if bbox.get("width", 0) > 0 and bbox.get("height", 0) > 0:
                    bbox_obj = BoundingBox(**bbox)
            
            sanity_check = IndividualCheck(
                check_id="0_mamad_identification",
                check_name="×–×™×”×•×™ ×××´×“ ×‘×ª×•×›× ×™×ª",
                description="×•×™×“×•× ×©×”××¢×¨×›×ª ××–×”×” × ×›×•×Ÿ ××ª ×—×“×¨ ×”×××´×“ ×•×œ× ×©×™×¨×•×ª×™×/××—×¡×Ÿ/××¨×•×Ÿ",
                status=CheckStatus.PASS if is_identified and confidence > 0.7 else CheckStatus.FAIL,
                plan_image_url=plan_blob_url,
                bounding_box=bbox_obj,
                reasoning=mamad_identification.get("reasoning", "") + f" (×¨××ª ×‘×™×˜×—×•×Ÿ: {int(confidence*100)}%)",
                violation=None if is_identified else ValidationViolation(
                    rule_id="mamad_id",
                    section_reference="0",
                    category="×–×™×”×•×™ ×××´×“",
                    severity="CRITICAL",
                    description="×”××¢×¨×›×ª ×œ× ×”×¦×œ×™×—×” ×œ×–×”×•×ª ×—×“×¨ ×××´×“ ×‘×ª×•×›× ×™×ª",
                    actual_value="×œ× ×–×•×”×”",
                    expected_value="×–×™×”×•×™ ×—×“-××©××¢×™ ×©×œ ×—×“×¨ ×××´×“",
                    location_description="×”×ª××•× ×” ×›×•×œ×”",
                    bounding_box=None
                )
            )
            checks.append(sanity_check)
        
        # Check data quality
        confidence = extracted_data.confidence_score if extracted_data.confidence_score is not None else 0.0
        is_low_confidence = confidence < 0.3
        
        missing_critical_fields = []
        if extracted_data.external_wall_count is None:
            missing_critical_fields.append("××¡×¤×¨ ×§×™×¨×•×ª ×—×™×¦×•× ×™×™×")
        if not extracted_data.wall_thickness_cm:
            missing_critical_fields.append("×¢×•×‘×™ ×§×™×¨×•×ª")
        if extracted_data.room_height_m is None:
            missing_critical_fields.append("×’×•×‘×” ×—×“×¨")
        
        # Check 1: Data quality
        if is_low_confidence or missing_critical_fields:
            data_quality_violation = ValidationViolation(
                rule_id="1_data_quality",
                section_reference="0.0",
                category="data_quality",
                severity=ValidationSeverity.CRITICAL,
                description=f"××™×›×•×ª × ×ª×•× ×™× ×œ× ××¡×¤×§×ª. ×‘×™×˜×—×•×Ÿ: {confidence*100:.1f}%. ×—×¡×¨: {', '.join(missing_critical_fields) if missing_critical_fields else '××™×Ÿ'}",
                expected_value="×‘×™×˜×—×•×Ÿ â‰¥30% + × ×ª×•× ×™× ×§×¨×™×˜×™×™×",
                actual_value=f"{confidence*100:.1f}%",
                location_description="×›×œ×œ ×”×ª×•×›× ×™×ª",
                bounding_box=None
            )
            
            data_quality_check = IndividualCheck(
                check_id="1_data_quality",
                check_name="××™×›×•×ª ×–×™×”×•×™ × ×ª×•× ×™×",
                description="×‘×“×™×§×” ×©×”××¢×¨×›×ª ×”×¦×œ×™×—×” ×œ×—×œ×¥ ××¡×¤×™×§ × ×ª×•× ×™× ××”×ª×•×›× ×™×ª",
                status=CheckStatus.FAIL,
                plan_image_url=plan_blob_url,
                bounding_box=None,
                reasoning=f"×‘×™×˜×—×•×Ÿ × ××•×š ({confidence*100:.1f}%) ××• × ×ª×•× ×™× ×—×¡×¨×™×: {', '.join(missing_critical_fields)}",
                violation=data_quality_violation
            )
            checks.append(data_quality_check)
        else:
            # Data quality passed
            data_quality_check = IndividualCheck(
                check_id="1_data_quality",
                check_name="××™×›×•×ª ×–×™×”×•×™ × ×ª×•× ×™×",
                description="×‘×“×™×§×” ×©×”××¢×¨×›×ª ×”×¦×œ×™×—×” ×œ×—×œ×¥ ××¡×¤×™×§ × ×ª×•× ×™× ××”×ª×•×›× ×™×ª",
                status=CheckStatus.PASS,
                plan_image_url=plan_blob_url,
                bounding_box=None,
                reasoning=f"×‘×™×˜×—×•×Ÿ ×’×‘×•×” ({confidence*100:.1f}%) ×•×›×œ ×”× ×ª×•× ×™× ×”×§×¨×™×˜×™×™× ×–×•×”×•",
                violation=None
            )
            checks.append(data_quality_check)
        
        # Create individual checks for each violation category
        check_id_counter = 2
        violation_by_category = {}
        
        for v in violations:
            if v.category not in violation_by_category:
                violation_by_category[v.category] = []
            violation_by_category[v.category].append(v)
        
        # Create a check for each violation
        for violation in violations:
            # Skip data quality violations (already handled)
            if violation.category == "data_quality":
                continue
                
            check = IndividualCheck(
                check_id=f"{check_id_counter}_{violation.category}",
                check_name=self._get_check_name_hebrew(violation.category),
                description=violation.description,
                status=CheckStatus.FAIL,
                plan_image_url=plan_blob_url,
                bounding_box=violation.bounding_box,
                reasoning=f"{violation.description}. × ××“×“: {violation.actual_value}, × ×“×¨×©: {violation.expected_value}",
                violation=violation
            )
            checks.append(check)
            check_id_counter += 1
        
        # Add passed checks for categories without violations
        all_categories = {
            "wall_thickness": "×¢×•×‘×™ ×§×™×¨×•×ª",
            "wall_count": "××¡×¤×¨ ×§×™×¨×•×ª ×—×™×¦×•× ×™×™×", 
            "room_height": "×’×•×‘×” ×—×“×¨",
            "room_volume": "× ×¤×— ×—×“×¨",
            "door_spacing": "××¨×—×§×™ ×“×œ×ª",
            "window_spacing": "××¨×—×§×™ ×—×œ×•×Ÿ",
            "ventilation": "××•×•×¨×•×¨",
        }
        
        for category, name in all_categories.items():
            if category not in violation_by_category and extracted_data:
                # Check if we have data for this category
                has_data = self._has_data_for_category(category, extracted_data)
                if has_data:
                    check = IndividualCheck(
                        check_id=f"{check_id_counter}_{category}",
                        check_name=name,
                        description=f"×‘×“×™×§×ª {name} - ×¢×‘×¨ ×‘×”×¦×œ×—×”",
                        status=CheckStatus.PASS,
                        plan_image_url=plan_blob_url,
                        bounding_box=None,
                        reasoning=f"{name} ×¢×•××“ ×‘×“×¨×™×©×•×ª ×”×ª×§×Ÿ",
                        violation=None
                    )
                    checks.append(check)
                    check_id_counter += 1
        
        # Calculate totals
        total_checks = len(checks)
        failed_checks = sum(1 for c in checks if c.status == CheckStatus.FAIL)
        passed_checks = sum(1 for c in checks if c.status == CheckStatus.PASS)
        
        # Determine overall status
        has_critical = any(c.violation and c.violation.severity == ValidationSeverity.CRITICAL for c in checks if c.violation)
        status = ValidationStatus.FAIL if has_critical or failed_checks > 0 else ValidationStatus.PASS
        
        return ValidationResult(
            id=validation_id,
            project_id=project_id,
            plan_name=plan_name,
            plan_blob_url=plan_blob_url,
            extracted_data=extracted_data,
            checks=checks,
            violations=violations,  # Keep for backward compatibility
            total_checks=total_checks,
            passed_checks=passed_checks,
            failed_checks=failed_checks,
            status=status
        )
    
    def _get_check_name_hebrew(self, category: str) -> str:
        """Get Hebrew name for check category."""
        names = {
            "wall_thickness": "×¢×•×‘×™ ×§×™×¨×•×ª",
            "wall_count": "××¡×¤×¨ ×§×™×¨×•×ª ×—×™×¦×•× ×™×™×",
            "room_height": "×’×•×‘×” ×—×“×¨",
            "room_volume": "× ×¤×— ×—×“×¨",
            "door_spacing": "××¨×—×§×™ ×“×œ×ª",
            "window_spacing": "××¨×—×§×™ ×—×œ×•×Ÿ",
            "ventilation": "××•×•×¨×•×¨",
            "data_quality": "××™×›×•×ª × ×ª×•× ×™×"
        }
        return names.get(category, category)
    
    def _has_data_for_category(self, category: str, data: ExtractedPlanData) -> bool:
        """Check if we have data for a specific category."""
        category_fields = {
            "wall_thickness": lambda d: d.wall_thickness_cm is not None and len(d.wall_thickness_cm) > 0,
            "wall_count": lambda d: d.external_wall_count is not None,
            "room_height": lambda d: d.room_height_m is not None,
            "room_volume": lambda d: d.room_volume_m3 is not None,
            "door_spacing": lambda d: d.door_spacing_internal_cm is not None or d.door_spacing_external_cm is not None,
            "window_spacing": lambda d: d.window_spacing_cm is not None,
            "ventilation": lambda d: d.has_ventilation_note is not None or d.has_air_inlet_pipe is not None,
        }
        
        checker = category_fields.get(category)
        return checker(data) if checker else False


# Singleton instance
_llm_validator_instance = None


def get_llm_validator() -> LLMValidator:
    """Get singleton LLM validator instance."""
    global _llm_validator_instance
    if _llm_validator_instance is None:
        _llm_validator_instance = LLMValidator()
    return _llm_validator_instance
